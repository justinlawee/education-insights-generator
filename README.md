# Innovare AI Lab â€“ Kâ€“12 Insight Generator

### ğŸ§  Turning Educational Data Into Actionable Insights

This repository contains the full **AI Insight Generation** and **Evaluation** system developed during the **Kellogg AI Lab Ã— Innovare** collaboration.  
It uses **LLMs, multi-agent workflows, and educational data pipelines** to automatically generate, visualize, and evaluate insights from Kâ€“12 assessment datasets.

---

## ğŸš€ Project Overview

**Goal:**  
Empower educators and school leaders to interpret large-scale student performance data â€” turning spreadsheets into narratives and guiding questions using AI.

**Solution:**  
An end-to-end AI pipeline that connects **BigQuery**, **LangChain**, and **Streamlit**, orchestrated through a multi-agent system (n8n + Lovable).  
The system performs:

1. **Data Ingestion** â€“ pulls Kâ€“12 assessment data (e.g., IAR Math & ELA) from BigQuery.  
2. **Insight Generation** â€“ uses prompt-driven LLMs to surface key findings and next-step questions.  
3. **Visualization** â€“ builds interactive charts and summaries for district, school, and subgroup performance.  
4. **Evaluation (Judge LLM)** â€“ scores each generated insight for clarity, actionability, and accuracy.  
5. **Feedback Loop** â€“ integrates structured rubric scores back into the workflow to improve future outputs.

---

## ğŸ§© Architecture
```
BigQuery â”€â–¶ ETL / Data Schema â”€â–¶ LLM Insight Generator (LangChain) â”€â–¶
Visualization (Streamlit / Plotly) â”€â–¶ Judge LLM Evaluation â”€â–¶ Feedback & Storage


### Core Components

| Layer | Description |
|-------|--------------|
| **Data Layer** | BigQuery tables for Kâ€“12 assessment (IAR Math & ELA). |
| **Processing Layer** | Python utilities for data cleaning and schema alignment (`src/bq_functions.py`, `src/utils.py`). |
| **AI Layer** | Insight generation via prompt templates and LLM orchestration (`src/prompts.py`, `src/workflow.py`). |
| **Visualization Layer** | Dashboards and report generation using Streamlit & Plotly (`innovare_dashboard.ipynb`). |
| **Evaluation Layer** | â€œJudge LLMâ€ that scores insights using a rubric for quality and bias detection. |
| **Automation Layer** | Multi-agent workflow designed in **n8n**, with optional **Lovable** front-end for nontechnical users. |
```
---

## ğŸ“‚ Repository Structure

```
education-insights-generator/
â”‚
â”œâ”€â”€ src/ # Core logic and modular utilities
â”‚ â”œâ”€â”€ workflow.py
â”‚ â”œâ”€â”€ utils.py
â”‚ â”œâ”€â”€ settings.py
â”‚ â”œâ”€â”€ prompts.py
â”‚ â”œâ”€â”€ bq_functions.py
â”‚ â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ notebooks/ # Jupyter exploration & insight notebooks
â”‚ â”œâ”€â”€ CleanVersion_QGenerator.ipynb
â”‚ â”œâ”€â”€ Insight_Generation_Consolidation.ipynb
â”‚ â”œâ”€â”€ VisGenerator.ipynb
â”‚ â”œâ”€â”€ innovare_dashboard.ipynb
â”‚ â”œâ”€â”€ Judge_LLM.ipynb - Colab.pdf
â”‚ â””â”€â”€ Insights Matrix.xlsx - Sheet1.pdf
â”‚
â”œâ”€â”€ data_samples/ # De-identified sample data
â”‚ â”œâ”€â”€ tables_descriptions.csv
â”‚ â”œâ”€â”€ iar_math_sample.csv
â”‚ â””â”€â”€ iar_ela_sample.csv
â”‚
â”œâ”€â”€ schema/ # Table schemas & metadata
â”‚ â””â”€â”€ schema.json
â”‚
â”œâ”€â”€ docs/ # Supporting documentation
â”‚ â”œâ”€â”€ README_DATA.md
â”‚ â”œâ”€â”€ README_GCLOUD.md
â”‚ â”œâ”€â”€ README_TABLES.md
â”‚ â”œâ”€â”€ AI Lab Spring Final Presentation (2).pdf
â”‚ â”œâ”€â”€ Insights Matrix.xlsx - Sheet1.pdf
â”‚ â””â”€â”€ innovare_n8n.json (private version omitted)
â”‚
â”œâ”€â”€ requirements.txt # Dependencies (LangChain, BigQuery, Streamlit, etc.)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md # This file
```

---

## âš™ï¸ Tech Stack

| Layer | Technologies |
|-------|---------------|
| **Language / Frameworks** | Python Â· LangChain Â· Streamlit Â· Pandas Â· Plotly |
| **LLM Access** | Google Vertex AI Â· Gemini 1.5 Pro Â· Groq API |
| **Data & Infra** | BigQuery Â· GCP SDK Â· n8n Automation |
| **Evaluation** | Custom â€œJudge LLMâ€ rubric system with prompt templating |
| **Visualization** | Streamlit Dashboards Â· Plotly Graphs |
| **Collaboration** | Lovable (for low-code workflow building) |

---

## ğŸ§® Sample Workflow

```python
from src.workflow import generate_insights
from src.settings import PROJECT_ID, DATASET_ID

df = generate_insights(
    project_id=PROJECT_ID,
    dataset_id=DATASET_ID,
    table="iar_math",
    llm_model="gemini-1.5-pro"
)
```

This function:
1. Queries BigQuery for assessment data.
2. Structures it into schema-aligned JSON.
3. Passes it through a prompt template.
4. Returns generated insights + AI-evaluated scores.

---

## ğŸ“Š Example Outputs

Example	Description
Insight:	â€œ5th grade math proficiency grew 8 points year-over-year, driven by subgroup improvements in Hispanic and EL populations.â€
Judge LLM Score:	4.6 / 5 â€” â€œClear, actionable, and supported by data.â€
Next Step Prompt:	â€œHow might schools with >70% growth maintain gains next year?â€

See Judge_LLM.ipynb for the scoring pipeline and examples.

## ğŸ§  Evaluation Framework (Judge LLM)

The **Judge LLM** evaluates insight quality across the following dimensions:

| Dimension | Description |
|------------|--------------|
| **Accuracy** | Alignment with underlying data |
| **Clarity** | Ease of interpretation by educators |
| **Actionability** | Whether the insight suggests next steps |
| **Bias Detection** | Flags overgeneralization or inequitable framing |

**Evaluation pipeline code lives in:**
- `notebooks/Judge_LLM.ipynb`
- `docs/Insights Matrix.xlsx - Sheet1.pdf`

---

## ğŸ”’ Privacy Notes

- All datasets in this repo are synthetic and de-identified.
- Real assessment data was stored in BigQuery and is not included here.
- innovare_n8n.json has been sanitized â€” API keys and internal endpoints removed.

---

ğŸ“ Additional Materials

- ğŸ¥ [Demo Video (YouTube)](https://youtu.be/713CubB-iXM)
- ğŸ§¾ [Final Presentation (Google Drive)](https://drive.google.com/file/d/1KGBahx3mkoWIHvbtndkx1bl0wV25w8ij)
- âš™ï¸ [n8n Multi-Agent Flow (redacted JSON)](https://drive.google.com/file/d/1xUvA4_uastxhl175A02g-8PWJuA-n8Sc)

---

## â­ï¸ Key Takeaways

Built a real applied AI system connecting LLMs, data pipelines, and human evaluation loops.
Demonstrates hands-on understanding of LLM operations, orchestration (n8n), and AI product strategy.
Serves as a blueprint for AI-assisted insight generation in any domain (education, analytics, or enterprise data).

---

## ğŸ« About

Developed by:
Justin Borenstein-Lawee
MBA Candidate Â· Kellogg School of Management

In collaboration with:
Kellogg AI Lab (Spring 2025)
